{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from src.utility import *\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import random\n",
    "import joblib\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"rl_scheduling\"\n",
    "createfolder(\"./data\")\n",
    "createfolder(\"./model\")\n",
    "createfolder(\"./result\")\n",
    "createfolder(\"./graph\")\n",
    "\n",
    "data_path = './data'\n",
    "model_path = './model'\n",
    "result_path = './result'\n",
    "graph_path = './graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file is loaded from ./data/raw data.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100001 entries, 0 to 100000\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   number     100001 non-null  int64  \n",
      " 1   status     100001 non-null  object \n",
      " 2   low-lime   100001 non-null  float64\n",
      " 3   high-lime  100001 non-null  float64\n",
      " 4   oyster     100001 non-null  float64\n",
      " 5   clam       100001 non-null  float64\n",
      " 6   mussel     100001 non-null  float64\n",
      " 7   purity     100001 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 6.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>low-lime</th>\n",
       "      <th>high-lime</th>\n",
       "      <th>oyster</th>\n",
       "      <th>clam</th>\n",
       "      <th>mussel</th>\n",
       "      <th>purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100001.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50001.000000</td>\n",
       "      <td>1854.981461</td>\n",
       "      <td>1855.018550</td>\n",
       "      <td>1854.981571</td>\n",
       "      <td>274.149776</td>\n",
       "      <td>1854.981571</td>\n",
       "      <td>0.885544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28867.946472</td>\n",
       "      <td>1184.032705</td>\n",
       "      <td>1184.032721</td>\n",
       "      <td>1184.032534</td>\n",
       "      <td>174.989255</td>\n",
       "      <td>1184.032534</td>\n",
       "      <td>0.123076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25001.000000</td>\n",
       "      <td>824.444444</td>\n",
       "      <td>824.444444</td>\n",
       "      <td>824.444444</td>\n",
       "      <td>121.845510</td>\n",
       "      <td>824.444444</td>\n",
       "      <td>0.877610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50001.000000</td>\n",
       "      <td>1648.888890</td>\n",
       "      <td>2061.111110</td>\n",
       "      <td>1648.888890</td>\n",
       "      <td>243.691020</td>\n",
       "      <td>1648.888890</td>\n",
       "      <td>0.899795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75001.000000</td>\n",
       "      <td>2885.555560</td>\n",
       "      <td>2885.555560</td>\n",
       "      <td>2885.555560</td>\n",
       "      <td>426.459285</td>\n",
       "      <td>2885.555560</td>\n",
       "      <td>0.922952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100001.000000</td>\n",
       "      <td>3710.000000</td>\n",
       "      <td>3710.000000</td>\n",
       "      <td>3710.000000</td>\n",
       "      <td>548.304795</td>\n",
       "      <td>3710.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              number       low-lime      high-lime         oyster  \\\n",
       "count  100001.000000  100001.000000  100001.000000  100001.000000   \n",
       "mean    50001.000000    1854.981461    1855.018550    1854.981571   \n",
       "std     28867.946472    1184.032705    1184.032721    1184.032534   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%     25001.000000     824.444444     824.444444     824.444444   \n",
       "50%     50001.000000    1648.888890    2061.111110    1648.888890   \n",
       "75%     75001.000000    2885.555560    2885.555560    2885.555560   \n",
       "max    100001.000000    3710.000000    3710.000000    3710.000000   \n",
       "\n",
       "                clam         mussel         purity  \n",
       "count  100001.000000  100001.000000  100001.000000  \n",
       "mean      274.149776    1854.981571       0.885544  \n",
       "std       174.989255    1184.032534       0.123076  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%       121.845510     824.444444       0.877610  \n",
       "50%       243.691020    1648.888890       0.899795  \n",
       "75%       426.459285    2885.555560       0.922952  \n",
       "max       548.304795    3710.000000       1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data = loadfile(data_path, \"raw data\", 'csv')\n",
    "display(raw_data.info())\n",
    "display(raw_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "input_var   = [\"low-lime\", 'high-lime', 'oyster', 'clam', 'mussel']\n",
    "output_var  = [\"purity\"]\n",
    "process_var = input_var + output_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import dnn\n",
    "\n",
    "num_x = len(input_var)\n",
    "num_y = len(output_var)\n",
    "num_layers = 3\n",
    "num_neurons = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN = dnn.DNN(raw_data, input_var, output_var, num_layers, num_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2188/2188 - 2s - loss: 0.0177 - val_loss: 0.0161 - 2s/epoch - 1ms/step\n",
      "Epoch 2/1000\n",
      "2188/2188 - 2s - loss: 0.0142 - val_loss: 0.0153 - 2s/epoch - 903us/step\n",
      "Epoch 3/1000\n",
      "2188/2188 - 2s - loss: 0.0141 - val_loss: 0.0152 - 2s/epoch - 867us/step\n",
      "Epoch 4/1000\n",
      "2188/2188 - 2s - loss: 0.0139 - val_loss: 0.0150 - 2s/epoch - 899us/step\n",
      "Epoch 5/1000\n",
      "2188/2188 - 2s - loss: 0.0138 - val_loss: 0.0150 - 2s/epoch - 821us/step\n",
      "Epoch 6/1000\n",
      "2188/2188 - 2s - loss: 0.0137 - val_loss: 0.0147 - 2s/epoch - 863us/step\n",
      "Epoch 7/1000\n",
      "2188/2188 - 2s - loss: 0.0134 - val_loss: 0.0147 - 2s/epoch - 866us/step\n",
      "Epoch 8/1000\n",
      "2188/2188 - 2s - loss: 0.0132 - val_loss: 0.0143 - 2s/epoch - 837us/step\n",
      "Epoch 9/1000\n",
      "2188/2188 - 2s - loss: 0.0130 - val_loss: 0.0142 - 2s/epoch - 830us/step\n",
      "Epoch 10/1000\n",
      "2188/2188 - 2s - loss: 0.0127 - val_loss: 0.0143 - 2s/epoch - 867us/step\n",
      "Epoch 11/1000\n",
      "2188/2188 - 2s - loss: 0.0125 - val_loss: 0.0136 - 2s/epoch - 845us/step\n",
      "Epoch 12/1000\n",
      "2188/2188 - 2s - loss: 0.0123 - val_loss: 0.0131 - 2s/epoch - 844us/step\n",
      "Epoch 13/1000\n",
      "2188/2188 - 2s - loss: 0.0123 - val_loss: 0.0132 - 2s/epoch - 871us/step\n",
      "Epoch 14/1000\n",
      "2188/2188 - 2s - loss: 0.0121 - val_loss: 0.0134 - 2s/epoch - 829us/step\n",
      "Epoch 15/1000\n",
      "2188/2188 - 2s - loss: 0.0119 - val_loss: 0.0129 - 2s/epoch - 863us/step\n",
      "Epoch 16/1000\n",
      "2188/2188 - 2s - loss: 0.0119 - val_loss: 0.0127 - 2s/epoch - 963us/step\n",
      "Epoch 17/1000\n",
      "2188/2188 - 2s - loss: 0.0118 - val_loss: 0.0127 - 2s/epoch - 828us/step\n",
      "Epoch 18/1000\n",
      "2188/2188 - 2s - loss: 0.0119 - val_loss: 0.0133 - 2s/epoch - 780us/step\n",
      "Epoch 19/1000\n",
      "2188/2188 - 2s - loss: 0.0118 - val_loss: 0.0137 - 2s/epoch - 809us/step\n",
      "Epoch 20/1000\n",
      "2188/2188 - 2s - loss: 0.0117 - val_loss: 0.0126 - 2s/epoch - 796us/step\n",
      "Epoch 21/1000\n",
      "2188/2188 - 2s - loss: 0.0132 - val_loss: 0.0148 - 2s/epoch - 775us/step\n",
      "Epoch 22/1000\n",
      "2188/2188 - 2s - loss: 0.0129 - val_loss: 0.0135 - 2s/epoch - 806us/step\n",
      "Epoch 23/1000\n",
      "2188/2188 - 2s - loss: 0.0121 - val_loss: 0.0130 - 2s/epoch - 761us/step\n",
      "Epoch 24/1000\n",
      "2188/2188 - 2s - loss: 0.0118 - val_loss: 0.0127 - 2s/epoch - 893us/step\n",
      "Epoch 25/1000\n",
      "2188/2188 - 2s - loss: 0.0118 - val_loss: 0.0135 - 2s/epoch - 808us/step\n",
      "Epoch 26/1000\n",
      "2188/2188 - 2s - loss: 0.0117 - val_loss: 0.0129 - 2s/epoch - 785us/step\n",
      "Epoch 27/1000\n",
      "2188/2188 - 2s - loss: 0.0117 - val_loss: 0.0126 - 2s/epoch - 944us/step\n",
      "Epoch 28/1000\n",
      "2188/2188 - 2s - loss: 0.0116 - val_loss: 0.0128 - 2s/epoch - 783us/step\n",
      "Epoch 29/1000\n",
      "2188/2188 - 2s - loss: 0.0117 - val_loss: 0.0141 - 2s/epoch - 732us/step\n",
      "Epoch 30/1000\n",
      "2188/2188 - 2s - loss: 0.0116 - val_loss: 0.0127 - 2s/epoch - 766us/step\n",
      "Epoch 31/1000\n",
      "2188/2188 - 2s - loss: 0.0121 - val_loss: 0.0133 - 2s/epoch - 798us/step\n",
      "Epoch 32/1000\n",
      "2188/2188 - 2s - loss: 0.0117 - val_loss: 0.0126 - 2s/epoch - 723us/step\n",
      "Epoch 33/1000\n",
      "2188/2188 - 2s - loss: 0.0116 - val_loss: 0.0125 - 2s/epoch - 772us/step\n",
      "Epoch 34/1000\n",
      "2188/2188 - 2s - loss: 0.0115 - val_loss: 0.0123 - 2s/epoch - 843us/step\n",
      "Epoch 35/1000\n",
      "2188/2188 - 2s - loss: 0.0116 - val_loss: 0.0130 - 2s/epoch - 815us/step\n",
      "Epoch 36/1000\n",
      "2188/2188 - 2s - loss: 0.0114 - val_loss: 0.0127 - 2s/epoch - 789us/step\n",
      "Epoch 37/1000\n",
      "2188/2188 - 2s - loss: 0.0114 - val_loss: 0.0142 - 2s/epoch - 963us/step\n",
      "Epoch 38/1000\n",
      "2188/2188 - 2s - loss: 0.0115 - val_loss: 0.0125 - 2s/epoch - 986us/step\n",
      "Epoch 39/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0126 - 2s/epoch - 828us/step\n",
      "Epoch 40/1000\n",
      "2188/2188 - 2s - loss: 0.0114 - val_loss: 0.0126 - 2s/epoch - 856us/step\n",
      "Epoch 41/1000\n",
      "2188/2188 - 2s - loss: 0.0114 - val_loss: 0.0124 - 2s/epoch - 1ms/step\n",
      "Epoch 42/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0122 - 2s/epoch - 923us/step\n",
      "Epoch 43/1000\n",
      "2188/2188 - 2s - loss: 0.0114 - val_loss: 0.0131 - 2s/epoch - 774us/step\n",
      "Epoch 44/1000\n",
      "2188/2188 - 2s - loss: 0.0114 - val_loss: 0.0125 - 2s/epoch - 744us/step\n",
      "Epoch 45/1000\n",
      "2188/2188 - 2s - loss: 0.0114 - val_loss: 0.0124 - 2s/epoch - 814us/step\n",
      "Epoch 46/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0122 - 2s/epoch - 738us/step\n",
      "Epoch 47/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0127 - 2s/epoch - 776us/step\n",
      "Epoch 48/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0126 - 2s/epoch - 825us/step\n",
      "Epoch 49/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0123 - 2s/epoch - 761us/step\n",
      "Epoch 50/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0123 - 2s/epoch - 766us/step\n",
      "Epoch 51/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0122 - 2s/epoch - 897us/step\n",
      "Epoch 52/1000\n",
      "2188/2188 - 2s - loss: 0.0115 - val_loss: 0.0134 - 2s/epoch - 818us/step\n",
      "Epoch 53/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0129 - 2s/epoch - 846us/step\n",
      "Epoch 54/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0123 - 2s/epoch - 795us/step\n",
      "Epoch 55/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0121 - 2s/epoch - 783us/step\n",
      "Epoch 56/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0124 - 2s/epoch - 785us/step\n",
      "Epoch 57/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0133 - 2s/epoch - 763us/step\n",
      "Epoch 58/1000\n",
      "2188/2188 - 2s - loss: 0.0113 - val_loss: 0.0122 - 2s/epoch - 734us/step\n",
      "Epoch 59/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0121 - 2s/epoch - 751us/step\n",
      "Epoch 60/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0122 - 2s/epoch - 823us/step\n",
      "Epoch 61/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0124 - 2s/epoch - 789us/step\n",
      "Epoch 62/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0123 - 2s/epoch - 756us/step\n",
      "Epoch 63/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0127 - 2s/epoch - 756us/step\n",
      "Epoch 64/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0128 - 2s/epoch - 1ms/step\n",
      "Epoch 65/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0122 - 2s/epoch - 868us/step\n",
      "Epoch 66/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0123 - 2s/epoch - 769us/step\n",
      "Epoch 67/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0125 - 2s/epoch - 724us/step\n",
      "Epoch 68/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0126 - 2s/epoch - 717us/step\n",
      "Epoch 69/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0125 - 2s/epoch - 723us/step\n",
      "Epoch 70/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0124 - 2s/epoch - 748us/step\n",
      "Epoch 71/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0125 - 2s/epoch - 822us/step\n",
      "Epoch 72/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0125 - 2s/epoch - 728us/step\n",
      "Epoch 73/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0121 - 2s/epoch - 757us/step\n",
      "Epoch 74/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0126 - 2s/epoch - 719us/step\n",
      "Epoch 75/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0121 - 2s/epoch - 745us/step\n",
      "Epoch 76/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0121 - 2s/epoch - 756us/step\n",
      "Epoch 77/1000\n",
      "2188/2188 - 2s - loss: 0.0110 - val_loss: 0.0123 - 2s/epoch - 739us/step\n",
      "Epoch 78/1000\n",
      "2188/2188 - 2s - loss: 0.0110 - val_loss: 0.0125 - 2s/epoch - 738us/step\n",
      "Epoch 79/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0123 - 2s/epoch - 770us/step\n",
      "Epoch 80/1000\n",
      "2188/2188 - 2s - loss: 0.0110 - val_loss: 0.0122 - 2s/epoch - 779us/step\n",
      "Epoch 81/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0122 - 2s/epoch - 781us/step\n",
      "Epoch 82/1000\n",
      "2188/2188 - 2s - loss: 0.0110 - val_loss: 0.0137 - 2s/epoch - 816us/step\n",
      "Epoch 83/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0137 - 2s/epoch - 854us/step\n",
      "Epoch 84/1000\n",
      "2188/2188 - 3s - loss: 0.0111 - val_loss: 0.0125 - 3s/epoch - 1ms/step\n",
      "Epoch 85/1000\n",
      "2188/2188 - 2s - loss: 0.0111 - val_loss: 0.0125 - 2s/epoch - 944us/step\n",
      "Epoch 86/1000\n",
      "2188/2188 - 2s - loss: 0.0110 - val_loss: 0.0125 - 2s/epoch - 816us/step\n",
      "Epoch 87/1000\n",
      "2188/2188 - 2s - loss: 0.0112 - val_loss: 0.0148 - 2s/epoch - 881us/step\n",
      "Epoch 88/1000\n",
      "2188/2188 - 2s - loss: 0.0121 - val_loss: 0.0131 - 2s/epoch - 846us/step\n",
      "Epoch 89/1000\n",
      "2188/2188 - 2s - loss: 0.0116 - val_loss: 0.0135 - 2s/epoch - 792us/step\n"
     ]
    }
   ],
   "source": [
    "DNN.train_test_split()\n",
    "DNN.scaler('minmax')\n",
    "DNN.model()\n",
    "DNN.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                300       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "284dd9de6cae4efa30855d8d79ffbe8c3d1ba871b5ea99b8217474c051980410"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('rl_scheduling': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
